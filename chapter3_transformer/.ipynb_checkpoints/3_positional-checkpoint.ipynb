{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181d3d5e-7335-472b-93d1-185aae5514be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\prac\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from bertviz.transformers_neuron_view import BertModel\n",
    "from bertviz.neuron_view import show\n",
    "from torch import nn\n",
    "from transformers import AutoConfig\n",
    "import torch\n",
    "from math import sqrt\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c2ce17b-3cdb-4b67-b44f-dfa289a695ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value):\n",
    "    dim_k = query.size(-1)\n",
    "    scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return torch.bmm(weights, value)\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, embed_dim, head_dim):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(embed_dim, head_dim)\n",
    "        self.k = nn.Linear(embed_dim, head_dim)\n",
    "        self.v = nn.Linear(embed_dim, head_dim)\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        attn_outputs = scaled_dot_product_attention(\n",
    "            self.q(hidden_state), self.k(hidden_state), self.v(hidden_state))\n",
    "        return attn_outputs\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        embed_dim = config.hidden_size #768\n",
    "        num_heads = config.num_attention_heads #12\n",
    "        head_dim = embed_dim // num_heads #64\n",
    "        self.heads = nn.ModuleList(\n",
    "            [AttentionHead(embed_dim, head_dim) for _ in range(num_heads)]\n",
    "        )#num_heads 만큼 어텐션 헤드 만들어줌\n",
    "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        x = torch.cat([h(hidden_state) for h in self.heads], dim=-1)#cat함수는 concatenate를 해주는 함수 옆으로 붙여준다.\n",
    "        # 12개의 헤드에서 64개가 나오니깐 12*64=768로 기존 embed_dim 차원을 복구\n",
    "        x = self.output_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73874a36-b48b-4375-a4fb-825776546bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\prac\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ckpt = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = BertModel.from_pretrained(model_ckpt)\n",
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "token_emb = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "text = \"time flies like an arrow\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
    "inputs_embeds = token_emb(inputs.input_ids)\n",
    "multihead_attn = MultiHeadAttention(config)\n",
    "attn_output = multihead_attn(inputs_embeds)\n",
    "attn_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4603010d-c286-4f26-80ad-801495081494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.linear_2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "'''\n",
    "여기서는 GELU를 사용함 음수부분에 작은 기울기로 작은 값을 넣어줌\n",
    "일반적으로는 RELU 사용하는 듯?\n",
    "이 네트워크 층의 의미를 잘 파악 못하겠음 \n",
    "어텐션에서 나온 정보를 X 입력으로 받고 이걸 네트워크에 통과하면 어떤 의미의 값이 출력으로 나오나??\n",
    "그냥 인코딩된 정보를 뭔가 압축하거나 합쳐주는 역할을 해주나?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c97247ec-cd3a-4da0-b1ca-7605072beada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_forward = FeedForward(config)\n",
    "ff_outputs = feed_forward(attn_output)\n",
    "ff_outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e92564-f323-4836-abbb-b9169077fe2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n위에서 구현한 FNN 층에 정규화 층 추가한것 그리고 스킵 커넥션 추가 (Resnet 사용할 때 Residual connection으로 알고 있었는데 찾아보니\\nskip connections이 작은 개념이라고 함)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layer_norm_1 = nn.LayerNorm(config.hidden_size)\n",
    "        self.layer_norm_2 = nn.LayerNorm(config.hidden_size)\n",
    "        self.attention = MultiHeadAttention(config)\n",
    "        self.feed_forward = FeedForward(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden_state = self.layer_norm_1(x)\n",
    "        x = x + self.attention(hidden_state)\n",
    "        x = x + self.feed_forward(self.layer_norm_2(x))\n",
    "        return x\n",
    "'''\n",
    "위에서 구현한 FNN 층에 정규화 층 추가한것 그리고 스킵 커넥션 추가 (Resnet 사용할 때 Residual connection으로 알고 있었는데 찾아보니\n",
    "skip connections이 작은 개념이라고 함)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f3e9b2e-b426-42c9-bc2d-bebe99a8136b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 768]), torch.Size([1, 5, 768]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layer = TransformerEncoderLayer(config)\n",
    "inputs_embeds.shape, encoder_layer(inputs_embeds).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf7900-9a97-4bdf-990a-4efb88d7e391",
   "metadata": {},
   "source": [
    "# 위치 임베딩(Positional encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4f02e5b-f18a-45b1-a5e3-22db1cf53138",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = nn.Embedding(config.vocab_size,config.hidden_size)#사용하는 토크나이저 크기에 맞게 임베딩 층\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings,config.hidden_size)#위치 임베딩 층\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        seq_length = input_ids.size(1) #[batch,seq_len,hidden]\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long).unsqueeze(0)#seq_len만큼 숫자를 올려줌 ex)5면 [0,1,2,3,4,5]이런식으로\n",
    "        #unsqueeze함수는 squeeze함수의 반대로 1인 차원을 생성하는 함수이다. 그래서 어느 차원에 1인 차원을 생성할 지 꼭 지정해주어야한다.\n",
    "        token_embeddings = self.token_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        embeddings = token_embeddings + position_embeddings #위치 정보를 더해줌\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6837bac6-5f18-4ee0-9a4e-af675a146a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embeddings = Embeddings(config)\n",
    "        self.layers = nn.ModuleList([TransformerEncoderLayer(config)\n",
    "                                     for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca8543bf-5164-4797-a50f-f56a3b3e7ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = TransformerEncoder(config)\n",
    "encoder(inputs.input_ids).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5eee941-39c2-4993-9fbd-e6b9488febb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerForSequenceClassification(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)[:, 0, :] # [CLS] 토큰의 은닉 상태를 선택합니다.\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce54fca5-f64f-4b91-bfa8-fc906df51e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.num_labels = 3\n",
    "encoder_classifier = TransformerForSequenceClassification(config)\n",
    "encoder_classifier(inputs.input_ids).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
