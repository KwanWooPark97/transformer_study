{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52660716-9e6f-44f9-9a2c-a86ef648d98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\prac\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "E:\\anaconda\\envs\\prac\\lib\\site-packages\\datasets\\load.py:1491: FutureWarning: The repository for emotion contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/emotion\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "m=\"distilbert-base-uncased\"\n",
    "from datasets import load_dataset\n",
    "\n",
    "emo=load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f20651-664d-44d6-b6bf-6129699422c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\prac\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7becd9785b3b4cf98825e02e82455d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "emotions_encoded = emo.map(tokenize, batched=True, batch_size=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "033a9216-3cde-4185-b653-61d0209f6e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels=6 \n",
    "\n",
    "model=(AutoModelForSequenceClassification.from_pretrained(m,num_labels=num_labels).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816bcb5b-9a49-4bc3-9002-5d33324afcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "def compute_metrics(pred):  #예측한 결과에 정확도랑 f1 score를 추가해주는 함수\n",
    "    labels=pred.label_ids\n",
    "    preds=pred.predictions.argmax(-1)\n",
    "    f1=f1_score(labels,preds,average=\"weighted\")\n",
    "    acc=accuracy_score(labels,preds)\n",
    "    return {\"accuracy\":acc,\"f1\":f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2753c55d-afa9-45ad-ab15-9d929c0b4ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ac8a45907745b9879e2314f7ea2812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9468aa18-0835-4dfa-b708-fe7e764fee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "logging_steps = len(emotions_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-emotion-0605\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=2, \n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  push_to_hub=True,\n",
    "                                  save_strategy=\"epoch\",\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  log_level=\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e2b2839-49da-4764-9fb4-d5ba4b7ba33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\prac\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "C:\\Users\\Owner\\jupyter\\chapter 2\\distilbert-base-uncased-finetuned-emotion-0605 is already a clone of https://huggingface.co/kwkwkwkwpark/distilbert-base-uncased-finetuned-emotion-0605. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "E:\\anaconda\\envs\\prac\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 01:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.176100</td>\n",
       "      <td>0.180491</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>0.930791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.163002</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.1441614761352539, metrics={'train_runtime': 111.7977, 'train_samples_per_second': 286.231, 'train_steps_per_second': 4.472, 'total_flos': 720342861696000.0, 'train_loss': 0.1441614761352539, 'epoch': 2.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args,\n",
    "                  train_dataset=emotions_encoded[\"train\"],\n",
    "                  eval_dataset=emotions_encoded[\"validation\"],\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f3c095-2467-43c7-b324-35247331c394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre=trainer.predict(emotions_encoded[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e377d62-cecd-4564-89a2-e8254b0ef2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.16300195455551147,\n",
       " 'test_accuracy': 0.9375,\n",
       " 'test_f1': 0.9376998527208639,\n",
       " 'test_runtime': 1.6048,\n",
       " 'test_samples_per_second': 1246.253,\n",
       " 'test_steps_per_second': 19.94}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01c030a4-9cb1-4fab-8470-a4e1d8231743",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emotions_hidden' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m y_pred\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39margmax(pre\u001b[38;5;241m.\u001b[39mpredictions,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m y_valid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43memotions_hidden\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      4\u001b[0m labels \u001b[38;5;241m=\u001b[39m emotions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfeatures[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m      5\u001b[0m plot_confusion_matrix(y_pred,y_valid,labels)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'emotions_hidden' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred=np.argmax(pre.predictions,axis=1)\n",
    "y_valid = np.array(emotions_hidden[\"validation\"][\"label\"])  # 내가 단위별로 코드를 나눠서 여기서 에러가 남 validataion 데이터 정답값을 가져옴\n",
    "labels = emo[\"train\"].features[\"label\"].names  \n",
    "plot_confusion_matrix(y_pred,y_valid,labels)  #가져온 데이터를 기준으로 오차 matrix를 보여줌 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
